
\begin{table}[ht]
\centering
\tiny
\caption{Classification results with mean $\pm$ standard deviation over folds}
\label{tab:classification_results}
\begin{tabularx}{\textwidth}{lXXXXXXXXXX}
\toprule
Train Fraction & Classifier & Top-1 Accuracy & Top-2 Accuracy & Top-3 Accuracy & F1 Macro & F1 Weighted & Precision Macro & Recall Macro & Specificity Macro & Balanced Accuracy \\
\midrule
0.10 & Logistic Regression & 0.775 ± 0.057 & N/A & N/A & 0.765 ± 0.063 & 0.773 ± 0.060 & 0.773 ± 0.058 & 0.767 ± 0.064 & 0.767 ± 0.064 & 0.767 ± 0.064 \\
0.10 & k-Nearest Neighbours & 0.755 ± 0.074 & N/A & N/A & 0.741 ± 0.079 & 0.751 ± 0.076 & 0.758 ± 0.083 & 0.740 ± 0.077 & 0.740 ± 0.077 & 0.740 ± 0.077 \\
0.30 & Logistic Regression & 0.801 ± 0.046 & N/A & N/A & 0.794 ± 0.047 & 0.800 ± 0.046 & 0.797 ± 0.048 & 0.795 ± 0.046 & 0.795 ± 0.046 & 0.795 ± 0.046 \\
0.30 & k-Nearest Neighbours & 0.772 ± 0.044 & N/A & N/A & 0.760 ± 0.048 & 0.769 ± 0.046 & 0.771 ± 0.048 & 0.757 ± 0.047 & 0.757 ± 0.047 & 0.757 ± 0.047 \\
0.50 & Logistic Regression & 0.812 ± 0.028 & N/A & N/A & 0.806 ± 0.029 & 0.812 ± 0.028 & \textbf{0.808 ± 0.029} & 0.807 ± 0.028 & 0.807 ± 0.028 & 0.807 ± 0.028 \\
0.50 & k-Nearest Neighbours & 0.784 ± 0.028 & N/A & N/A & 0.773 ± 0.030 & 0.781 ± 0.029 & 0.782 ± 0.030 & 0.769 ± 0.030 & 0.769 ± 0.030 & 0.769 ± 0.030 \\
0.70 & Logistic Regression & 0.812 ± 0.024 & N/A & N/A & \textbf{0.807 ± 0.025} & 0.812 ± 0.024 & 0.807 ± 0.025 & \textbf{0.808 ± 0.026} & \textbf{0.808 ± 0.026} & \textbf{0.808 ± 0.026} \\
0.70 & k-Nearest Neighbours & 0.790 ± 0.027 & N/A & N/A & 0.780 ± 0.028 & 0.788 ± 0.027 & 0.788 ± 0.029 & 0.776 ± 0.028 & 0.776 ± 0.028 & 0.776 ± 0.028 \\
1.00 & Logistic Regression & \textbf{0.813 ± 0.022} & N/A & N/A & 0.807 ± 0.023 & \textbf{0.813 ± 0.022} & 0.808 ± 0.023 & 0.808 ± 0.022 & 0.808 ± 0.022 & 0.808 ± 0.022 \\
1.00 & k-Nearest Neighbours & 0.799 ± 0.024 & N/A & N/A & 0.789 ± 0.025 & 0.797 ± 0.024 & 0.796 ± 0.025 & 0.786 ± 0.026 & 0.786 ± 0.026 & 0.786 ± 0.026 \\
\bottomrule
\bottomrule
\end{tabularx}
\end{table}
